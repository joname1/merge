name: Parallel URL Fetch

on:
  #å¦‚è¦ä½¿ç”¨å®šæ—¶è¿è¡Œï¼Œè¯·æŠŠä¸‹é¢ä¸¤è¡Œå¼€å¤´çš„#ç¬¦å·åˆ é™¤
  schedule:
  - cron: '*/180 * * * *'
  workflow_dispatch: 

jobs:
  fetch-urls:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Fetch URLs in parallel
      # secretsè®¾ç½®ï¼Œå˜é‡åç§°ï¼šhttp
      # å˜é‡å€¼è¦æ±‚ï¼šæ¯ä¸ªä¿æ´»/upç½‘é¡µæˆ–æ¯ä¸ªé‡å¯/reç½‘é¡µä¹‹é—´ç”¨ç©ºæ ¼æˆ–è€…ï¼Œæˆ–è€…,é—´éš”å¼€ï¼Œç½‘é¡µå‰å¸¦http://
      # å˜é‡å€¼å¡«å†™ç¤ºä¾‹ï¼šhttp://ä¿æ´»æˆ–é‡å¯ç½‘é¡µ1 http://ä¿æ´»æˆ–é‡å¯ç½‘é¡µ2 http://ä¿æ´»æˆ–é‡å¯ç½‘é¡µ3 â€¦â€¦â€¦
      run: |
        IFS=$',ï¼Œ ' read -r -a http <<< "${{ secrets.http }}"
         echo "*****************************************************"
        for url in "${http[@]}"; do
          response=$(curl -sk "$url" || true)
          if [[ "$response" == *"ç½‘é¡µä¿æ´»å¯åŠ¨"* ]]; then
          echo "ğŸ‰æ­å–œï¼$url âœ…è¿è¡Œæ­£å¸¸ï¼ŒæˆåŠŸæ‹‰èµ·ä¸€æ¬¡ä¿æ´»"
          elif [[ "$response" == *"ä¸»ç¨‹åºé‡å¯æˆåŠŸ"* ]]; then
          echo "ğŸ‰æ­å–œï¼$url âœ…è¿è¡Œæ­£å¸¸ï¼ŒæˆåŠŸé‡å¯ä¸€æ¬¡ä¸»ç¨‹åº"
          else
         echo "ğŸ’¥æ¯å…·ï¼$url âŒè¿è¡Œå¤±è´¥ï¼Œâš ï¸ç½‘é¡µå˜é‡æ˜¯å¦å¡«å†™æ­£ç¡®ï¼Ÿæˆ–è€…Serv00ç‚¸äº†"
         fi
        done
        wait
